{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "# Custom code\n",
    "from load_model import *\n",
    "from utils import *\n",
    "from augmentation import *\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where dataset is stored\n",
    "root_path = '/data/ASL'\n",
    "\n",
    "# Checkpoints get saved to './checkpoints/{run_name}_epoch{epoch}.pth.tar'\n",
    "checkpoint_every_N_epochs = 15 # You put N here\n",
    "run_name = '14classes' \n",
    "\n",
    "# Determines size of input volume into NN\n",
    "desired_frames = 16\n",
    "desired_size = (112, 112)\n",
    "\n",
    "# Computation settings\n",
    "num_threads = 16\n",
    "use_cuda = True\n",
    "\n",
    "# Val/Train parameters\n",
    "val_frac = .1  # Fraction of dataset set aside for validation set\n",
    "num_classes = 15  # Number of classes in output layer\n",
    "epochs = 100\n",
    "lower_lr_every_N_epochs = 20  # Divide LR by 2 every N epochs (you put N here)\n",
    "batch_size = 16\n",
    "learning_rate = .2\n",
    "\n",
    "# Settings for SGD optimizer\n",
    "momentum = .9\n",
    "dampening = .9\n",
    "weight_decay = .001\n",
    "\n",
    "# Set this to a filepath string if you want to continue training a pretrained model\n",
    "#load_checkpoint = \"checkpoints/14classes_epoch30.pth\"\n",
    "load_checkpoint = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Creating model architecture for mobilenetv2\n",
      ">> Successfully created model architecture for mobilenetv2.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "use_cuda was specified in generate_model(), but no cuda device was found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0c4255a7f2dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load in pretrained mobilenetv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = load_model(name=\"mobilenetv2\",\n\u001b[0m\u001b[1;32m      3\u001b[0m                   \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesired_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mwidth_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spyder/deepsign/training/load_model.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, num_classes, sample_size, width_mult, pretrain_path, use_cuda, transfer_learning)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmount_to_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrain_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spyder/deepsign/training/load_model.py\u001b[0m in \u001b[0;36mmount_to_gpu\u001b[0;34m(model, default_device)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount_to_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_cuda was specified in generate_model(), but no cuda device was found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: use_cuda was specified in generate_model(), but no cuda device was found."
     ]
    }
   ],
   "source": [
    "# Load in pretrained mobilenetv2\n",
    "model = load_model(name=\"mobilenetv2\",\n",
    "                  num_classes=num_classes,\n",
    "                  sample_size=desired_size[0],\n",
    "                  width_mult=1.0,\n",
    "                  pretrain_path=None,\n",
    "                  use_cuda=use_cuda,\n",
    "                  transfer_learning='last_layer')\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            momentum=momentum,\n",
    "            dampening=dampening,\n",
    "            weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if load_checkpoint:\n",
    "    print('>> Loading checkpoint: {}'.format(load_checkpoint))\n",
    "    save_info = torch.load(load_checkpoint)\n",
    "    start_epoch = save_info['epoch']\n",
    "    optimizer.load_state_dict(save_info['optimizer'])\n",
    "    model.load_state_dict(save_info['state_dict'])\n",
    "    history = save_info['history']\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that all layers are on cuda (if desired) and required_grad is set to true\n",
    "# for the layers you want to train\n",
    "for name, param in model.named_parameters():\n",
    "    device = param.device\n",
    "    param.requires_grad = False\n",
    "    \n",
    "    if name == 'module.classifier.weight':\n",
    "        param.requires_grad = True\n",
    "    if name == 'module.classifier.bias':\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    # Manual unfreeze the last couple layers for fine-tuning\n",
    "    if name == 'module.features.18.0.weight':\n",
    "        param.requires_grad = True\n",
    "    if name == 'module.features.18.1.weight':\n",
    "        param.requires_grad = True\n",
    "    elif name == 'module.features.18.1.bias':\n",
    "        param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For validation dataset, pick out a fraction of videos\n",
    "val_dataset = ASLDataset(root_path=root_path, desired_frames=desired_frames, desired_size=desired_size, val_frac=.1)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=min(64, len(val_dataset)), num_workers=num_threads,\n",
    "            pin_memory=True)\n",
    "\n",
    "# Feed validation metadata into the training dataset, so it knows to exclude videos found in validation set\n",
    "train_dataset = ASLDataset(root_path=root_path, desired_frames=16, desired_size=(112, 112), val_metadata=val_dataset.metadata)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_threads,\n",
    "            pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SANITY CHECK: Load in random training vid and make sure label matches video\n",
    "i = np.random.randint(0, len(val_dataset))\n",
    "x, y = val_dataset[i]\n",
    "%matplotlib notebook\n",
    "inv_codex = {v:k for k,v in train_dataset.codex.items()}\n",
    "label = inv_codex[y]\n",
    "print(\"Playing animation for '{}'.\".format(label))\n",
    "animate_movie(np.array(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, history):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('train_loss', ':.4e')\n",
    "    accuracies = []\n",
    "    for i in range(num_classes):\n",
    "        accuracies.append(AverageMeter('train_acc'+str(i+1), ':6.2f'))\n",
    "    \n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "\n",
    "        x = x.float()\n",
    "        y = y.long()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "        yhat = model(x)\n",
    "        loss = criterion(yhat, y)\n",
    "        acc = calculate_accuracy(yhat, y, topk=tuple(range(1,num_classes+1)))\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update tracking parameters\n",
    "        losses.update(loss.item(), x.size(0))\n",
    "        batch_time.update(time.time() - start_time)\n",
    "        for i in range(num_classes):\n",
    "            accuracies[i].update(acc[i], x.size(0))\n",
    "\n",
    "        # Print progress\n",
    "        print('{num_batch}/{total_batches} batches complete. train_loss: {loss.avg:.3f}. train_acc: {top1.avg:.3f}. Time: {batch_time.avg:.1f} sec. '.format(\n",
    "                  num_batch=i+1,\n",
    "                  total_batches=len(train_loader),\n",
    "                  batch_time=batch_time,\n",
    "                  loss=losses,\n",
    "                  top1=accuracies[0]), end='\\r')\n",
    "        \n",
    "    avg_accuracies = [acc.avg for acc in accuracies]\n",
    "    return avg_accuracies, losses.avg\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def validate(model, dataloader, criterion):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    losses = AverageMeter('val_loss', ':.4e')\n",
    "    accuracies = []\n",
    "    for i in range(num_classes):\n",
    "        accuracies.append(AverageMeter('val_acc'+str(i+1), ':6.2f'))\n",
    "    \n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "\n",
    "        x = x.float()\n",
    "        y = y.long()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "        yhat = model(x)\n",
    "        loss = criterion(yhat, y)\n",
    "        acc = calculate_accuracy(yhat, y, topk=tuple(range(1,num_classes+1)))\n",
    "        \n",
    "        # Update tracking parameters\n",
    "        losses.update(loss.item(), x.size(0))\n",
    "        for i in range(num_classes):\n",
    "            accuracies[i].update(acc[i], x.size(0))\n",
    "\n",
    "    avg_accuracies = [acc.avg for acc in accuracies]\n",
    "    return avg_accuracies, losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate validation loss/acc before any training occurs, as a reference point\n",
    "with torch.no_grad():\n",
    "    val_acc, val_loss = validate(model, val_loader, criterion)\n",
    "print('BEFORE TRAINING: val_loss = {:.4f}, val_acc = {:.4f} (top 50% = {:.4f})'.format(val_loss, val_acc[0], val_acc[int(num_classes/2)]))\n",
    "\n",
    "# Main training loop\n",
    "start_time = time.time()\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    \n",
    "    epoch_start = time.time()\n",
    "\n",
    "    if epoch % lower_lr_every_N_epochs == 0:\n",
    "        new_lr = learning_rate/2**int(epoch/lower_lr_every_N_epochs)\n",
    "        adjust_learning_rate(new_lr, optimizer)\n",
    "        print('Adjusted learning rate to: {}'.format(new_lr))\n",
    "    \n",
    "    train_acc, train_loss = train(model, train_loader, criterion, optimizer, history)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    \n",
    "    # validate\n",
    "    with torch.no_grad():\n",
    "        val_acc, val_loss = validate(model, val_loader, criterion)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "    \n",
    "    time_since_start = time.time() - start_time\n",
    "    avg_time_per_epoch = time_since_start/(epoch+1)\n",
    "    time_remaining = epochs*avg_time_per_epoch - time_since_start\n",
    "    print('\\n Completed epoch {}/{}. val_loss: {:.3f}. val_acc: {:.3f} (top 50%: {:.3f}). ETA: {:.1f} mins remaining.'.format(epoch+1, epochs, val_loss, val_acc[0], val_acc[int(num_classes/2)], time_remaining/60))\n",
    "    \n",
    "    if (epoch + 1) % checkpoint_every_N_epochs == 0:\n",
    "        filename = 'checkpoints/'+run_name+'_epoch'+str(epoch+1)+'.pth'\n",
    "        print('Saving checkpoint to: {}'.format(filename))\n",
    "        save_checkpoint({'epoch': epoch + 1, 'state_dict': model.state_dict(), 'val_acc1': val_acc, 'optimizer' : optimizer.state_dict(), 'history':history}, filename=filename)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss/accuracy vs epoch\n",
    "\n",
    "%matplotlib notebook\n",
    "train_loss = history['train_loss']\n",
    "val_loss = history['val_loss'] \n",
    "\n",
    "plt.plot(train_loss, label='Train')\n",
    "plt.plot(val_loss, label='Val')\n",
    "plt.legend()\n",
    "plt.title('Loss vs epoch')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()\n",
    "\n",
    "plt.figure(2)\n",
    "train_acc = [item[0] for item in history['train_acc']]\n",
    "val_acc = [item[0] for item in history['val_acc']]\n",
    "plt.plot(train_acc, label='Train')\n",
    "plt.plot(val_acc, label='Val')\n",
    "plt.legend()\n",
    "plt.title('Accuracy (top 1)')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()\n",
    "\n",
    "plt.figure(3)\n",
    "i = 3\n",
    "train_acc = [item[i] for item in history['train_acc']]\n",
    "val_acc = [item[i] for item in history['val_acc']]\n",
    "plt.plot(train_acc, label='Train')\n",
    "plt.plot(val_acc, label='Val')\n",
    "plt.legend()\n",
    "plt.title('Accuracy (top 50%)')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
