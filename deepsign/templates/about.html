{% extends "layout.html" %}
{% block content %}

    <center><h3>About this app</h3></center>
    <p>This app was a project I built as part of the Insight data science fellowship. All code written for this project, from neural network training to web app deployment,
        can be found <a href="https://github.com/jeffsrobertson/deepsign">here</a>.</p>
        <center><img src="{{ url_for('static', filename='collage.png') }}" width="80%"></center>
    <br>

    <center><h3>Gesture Recognition</h3></center>
    <p>Gesture recognition was achieved through a 3D convolutional neural network. In a 3D ConvNet,
        a sequence of frames are fed into the neural network as an input "volume".
        The kernel used in a Conv3D layer is also a volume, spanning height, width, and time,
        and so a Conv3D layer is able to extract spatial as well as temporal features.
        The model employed in this app is based on a 3D generalization of the MobileNetV2 architecture.</p>
<p>Because no open source dataset exists for animated ASL gestures (at least that I'm aware of),
    the biggest challenge was acquiring enough training data to effectively train a neural network.
    Rather than training a model from scratch, the model was first pretrained on the publicly available
    <a href="https://20bn.com/datasets/jester">Jester dataset</a>.</p>
        <br>
        <center>
            <video autoplay loop muted playsinline poster='' width="80%">
                <source src="{{ url_for('static', filename='jester.mp4') }}" type='video/mp4' >
            </video><br>
            <small class="text-muted">Taken from <a href="https://20bn.com/datasets/jester">20bn.com</a></small>
        </center>
        <br><p>The Jester dataset consists of ~150,000 videos of people performing hand gestures across 27 different categories.
        With this pretrained model, the last couple layers were retrained on a much smaller training set of ASL gesture videos
    (replacing the last classification layer with one of appropriate size).

        <center><h3>Copyright</h3></center>
        <p>There is none. Github link at the top for the complete source code to everything here. Download it, use it, sell it, go nuts.</p>

<!--No app/model/dataset exists for ASL gesture recognition. Data is severely laacking, and all training data was collected from online dictionaries. Words only consist of ~20 training videos, and while data augmentation was used,  -->

<!-- original paper to jester -->

<!--         The neural network used for gesture recognition was built in Pytorch,
        and trained on an AWS EC2 instance with parallel GPU computing. The-->

{% endblock content %}
